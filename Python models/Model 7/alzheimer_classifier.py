# -*- coding: utf-8 -*-
"""Alzheimer classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xqcsdMRHkW-AlQwEprSO5YxNIM3SOaF0

The used dataset, is a public Kaggle dataset. [Dataset](https://www.kaggle.com/datasets/uraninjo/augmented-alzheimer-mri-dataset?resource=download)
"""

!unrar x -Y "/content/dataset.rar" "/content/" # Decompressing the dataset

!pip install lime

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.imagenet_utils import preprocess_input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input, AveragePooling2D,Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard
import datetime, os
from tensorflow.keras.models import load_model
import cv2 
import lime
import numpy as np
from tensorflow.keras.preprocessing.image import img_to_array
import matplotlib.pyplot as plt
import tensorflow as tf
from keras.preprocessing import image
from keras.applications.imagenet_utils import decode_predictions
from lime import lime_image
from skimage.segmentation import mark_boundaries
from keras.applications import inception_v3 as inc_net

# Important paths
train_path = '/content/dataset/train'
test_path = '/content/dataset/validation'

# Dataset split => 20% => From the original dataset, the 20% of the pictures to the validation directory (hand-made)
width_shape = 200 # Image width
height_sape = 190 # Image height
num_labels = 4 # Number of classification labels
epochs = 4
batch_size = 32
label_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']

# Training and testing dataset configuration
training_dataset = ImageDataGenerator()
testing_dataset = ImageDataGenerator()

trainging_gen = training_dataset.flow_from_directory(
    train_path,
    target_size=(width_shape, height_sape),
    batch_size=batch_size,
    color_mode='grayscale',
    class_mode='categorical', shuffle=True)

testing_gen = testing_dataset.flow_from_directory(
    test_path,
    target_size=(width_shape, height_sape),
    batch_size=batch_size,
    color_mode='grayscale',
    class_mode='categorical', shuffle=True)

# Defining the architecture
model = Sequential()

# Convolutional layer 1
model.add(Conv2D(32, kernel_size=(3, 3), padding="same", activation="relu", strides=1, input_shape = (width_shape, height_sape, 1)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

# Convolutional layer 2
model.add(Conv2D(64, kernel_size=(5, 5), padding="same", activation="relu", strides=1))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

# Convolutional layer 3
model.add(Conv2D(128, kernel_size=(3, 3), padding="same", activation="relu", strides=1))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.2))


# Convolutional layer 4
model.add(Conv2D(256, kernel_size=(3, 3), padding = "same", activation="relu", strides=1))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.2))

# Data conversion
model.add(Flatten())

# Layer 6
model.add(Dense(1024))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.2))

# Classification
model.add(Dense(num_labels, activation='softmax'))

model.summary()

# Compilation and optimization
optimizer = Adam(learning_rate=0.01) # learning_rate=1e-4
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
# categorical crossentropy because the classification, is a multi-class class classification
# Decay parameter is how the learning_reate goes down in order not to miss the optimal point.
# In other words, the program has to decay learning rate to have more accurate steps by reducing the learning rate.

# Commented out IPython magic to ensure Python compatibility.
# TensorBoard
# %load_ext tensorboard
logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
callbacks = TensorBoard(logdir, histogram_freq=1)

# Training
model.fit(
    trainging_gen,
    epochs=epochs,
    validation_data=testing_gen,
    steps_per_epoch=trainging_gen.n//batch_size,
    validation_steps=testing_gen.n//batch_size,
    callbacks=[callbacks]
)

score = model.evaluate(testing_gen, verbose=0)
# Returns the loss value and metrics values for the model in test mode
print("Test loss = ", score[0])
print("Test accuracy = ", score[1])

# Commented out IPython magic to ensure Python compatibility.
# Performance graphic
# %tensorboard --logdir logs

# Pink = validation
#Green = Train

# Simple test
test_brains = []

pic_path = "/content/dataset/validation/VeryMildDemented/3dfe49f9-50ac-47c8-80ba-1eabe0fb2325.jpg"

test_brain = cv2.cvtColor(cv2.imread(pic_path), cv2.COLOR_BGR2GRAY)
test_brain = cv2.resize(test_brain, (190, 200))
test_brain2 = img_to_array(test_brain)
test_brain2 = np.expand_dims(test_brain2, axis=0)
test_brains.append(test_brain2)
prediction = model.predict(test_brains)

print("Top prediction: " + label_names[np.argmax(prediction)] + "\n")
percentages = []
for i in range(0, len(prediction[0])):
  percentages.append(round(prediction[0][i] * 100, 2))
print("Scorings: " + "\n")
print("Mildly demented: " + str(percentages[0]) + "%")
print("Moderately demented: " + str(percentages[1]) + "%")
print("Non-demented: " + str(percentages[2]) + "%")
print("Very mildly demented: " + str(percentages[3]) + "%")

"""## Using inception"""

inet_model = inc_net.InceptionV3()

out = []
img = tf.keras.utils.load_img(pic_path, target_size=(299, 299))
x = img_to_array(img)
x = np.expand_dims(x, axis=0)
x = inc_net.preprocess_input(x)
out.append(x)
vstack = np.vstack(out)[0]
plt.imshow(vstack / 2 + 0.55)

explainer = lime_image.LimeImageExplainer()
explanation = explainer.explain_instance(vstack.astype("double"), inet_model.predict, top_labels=4, hide_color=0, num_samples=1000)

temp, mask = explanation.get_image_and_mask(explanation.top_labels[3], positive_only=False, num_features=5, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

model.save("model_version_7.h5")